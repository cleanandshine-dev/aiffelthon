import torch
import numpy as np
from model import GAT
from dataset import AMLtoGraph
import torch_geometric.transforms as T
from torch_geometric.loader import NeighborLoader
from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score

# GPU/CPU ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ë°ì´í„°ì…‹ ë¡œë“œ
dataset = AMLtoGraph('./lej_dataset_002')
# ë¶„í• ëœ ë°ì´í„°ì…‹ì„ ê°ê° ë¡œë“œ
train_data = dataset.data_train.to(device)
val_data = dataset.data_val.to(device)
test_data = dataset.data_test.to(device)

# ì‚¬ê¸° ê³„ì¢Œ ë¹„ìœ¨ í™•ì¸ (ë¶ˆê· í˜• ë°ì´í„° ë³´ì •) - train ë°ì´í„° ê¸°ì¤€
fraud_ratio = (train_data.y == 1).sum().item() / train_data.y.shape[0]
pos_weight = torch.tensor([1.0 / fraud_ratio]).to(device)  # ë¶ˆê· í˜• ë³´ì •

# ëª¨ë¸ ì´ˆê¸°í™” (edge_attr í™œìš©)
model = GAT(
    in_channels=train_data.num_features, # train data ê¸°ì¤€ìœ¼ë¡œ input channel ì„¤ì •
    edge_dim=train_data.edge_attr.shape[1], # train data ê¸°ì¤€ìœ¼ë¡œ edge dimension ì„¤ì •
    hidden_channels=16,
    out_channels=1,
    heads=8
).to(device)

# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # ë¶ˆê· í˜• ë³´ì • ì ìš©
optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)

# ë°ì´í„° ë¡œë” ì„¤ì •
train_loader = NeighborLoader(train_data, num_neighbors=[30] * 2, batch_size=256, shuffle=True)
val_loader = NeighborLoader(val_data, num_neighbors=[30] * 2, batch_size=256, shuffle=False)  # ê²€ì¦ ë¡œë”
test_loader = NeighborLoader(test_data, num_neighbors=[30] * 2, batch_size=256, shuffle=False) # í…ŒìŠ¤íŠ¸ ë¡œë”

# Top-K í‰ê°€ í•¨ìˆ˜
def top_k_indices(y_score, k):
    """ ì˜ˆì¸¡ ì ìˆ˜(y_score)ì—ì„œ ìƒìœ„ Kê°œ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸° """
    return np.argsort(y_score)[-k:]

def precision_at_k(y_true, y_score, k=30):
    """ Precision@K ê³„ì‚°: ìƒìœ„ Kê°œ ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ ì‚¬ê¸° ë¹„ìœ¨ """
    top_k_idx = top_k_indices(y_score, k)
    y_top_k_pred = (y_score[top_k_idx] > 0.5).astype(int)
    y_top_k_true = y_true[top_k_idx]
    return precision_score(y_top_k_true, y_top_k_pred, average='binary')

def accuracy_at_k(y_true, y_score, k=30):
    """ Accuracy@K ê³„ì‚°: ìƒìœ„ Kê°œ ì˜ˆì¸¡ ì¤‘ ë§žì¶˜ ê°œìˆ˜ """
    top_k_idx = top_k_indices(y_score, k)
    y_top_k_pred = (y_score[top_k_idx] > 0.5).astype(int)
    y_top_k_true = y_true[top_k_idx]
    return accuracy_score(y_top_k_true, y_top_k_pred)

# í•™ìŠµ ë£¨í”„ ì„¤ì •
num_epochs = 30
best_f1 = 0  # ìµœê³  ì„±ëŠ¥ ì €ìž¥

for epoch in range(num_epochs):
    total_loss = 0
    model.train()

    for batch in train_loader:
        optimizer.zero_grad()
        batch.to(device)

        # ëª¨ë¸ ì˜ˆì¸¡ (sigmoid ë¯¸ì ìš©)
        pred = model(batch.x, batch.edge_index, batch.edge_attr).view(-1)

        # ì†ì‹¤ ê³„ì‚° (ì´ì§„ ë¶„ë¥˜)
        loss = criterion(pred, batch.y.float())
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    # ðŸ”¹ 10 epochë§ˆë‹¤ í‰ê°€ ì‹¤í–‰
    if epoch % 10 == 0:
        print(f'Epoch {epoch:03d} | Loss: {total_loss:.4f}')
        model.eval()

        # validation loop
        with torch.no_grad():
            all_preds, all_labels = [], []
            for batch in val_loader:
                batch.to(device)
                pred = torch.sigmoid(model(batch.x, batch.edge_index, batch.edge_attr).view(-1))
                all_preds.append(pred.cpu().numpy())
                all_labels.append(batch.y.cpu().numpy())

            all_preds = np.concatenate(all_preds)
            all_labels = np.concatenate(all_labels)

            f1 = f1_score(all_labels, (all_preds > 0.5).astype(int), average='binary')
            precision = precision_score(all_labels, (all_preds > 0.5).astype(int), average='binary')
            roc_auc = roc_auc_score(all_labels, all_preds)

            top_k_acc = accuracy_at_k(all_labels, all_preds, k=30)
            top_k_prec = precision_at_k(all_labels, all_preds, k=30)

            print(f'[Validation] F1-score: {f1:.4f}, Precision: {precision:.4f}, ROC-AUC: {roc_auc:.4f}')
            print(f'[Validation] Top-30 Accuracy: {top_k_acc:.4f}, Top-30 Precision: {top_k_prec:.4f}')


        # Test loop (í•™ìŠµ ê³¼ì •ì—ì„œ TestëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ.  ìµœì  ëª¨ë¸ ì„ íƒ í›„ Test)
        with torch.no_grad():
            all_preds, all_labels = [], []
            for batch in test_loader:
                batch.to(device)
                pred = torch.sigmoid(model(batch.x, batch.edge_index, batch.edge_attr).view(-1))
                all_preds.append(pred.cpu().numpy())
                all_labels.append(batch.y.cpu().numpy())

            all_preds = np.concatenate(all_preds)
            all_labels = np.concatenate(all_labels)

            f1 = f1_score(all_labels, (all_preds > 0.5).astype(int), average='binary')
            precision = precision_score(all_labels, (all_preds > 0.5).astype(int), average='binary')
            roc_auc = roc_auc_score(all_labels, all_preds)

            top_k_acc = accuracy_at_k(all_labels, all_preds, k=30)
            top_k_prec = precision_at_k(all_labels, all_preds, k=30)

            print(f'[Test] F1-score: {f1:.4f}, Precision: {precision:.4f}, ROC-AUC: {roc_auc:.4f}')
            print(f'[Test] Top-30 Accuracy: {top_k_acc:.4f}, Top-30 Precision: {top_k_prec:.4f}')