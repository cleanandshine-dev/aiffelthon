import datetime
import os
from typing import Optional, Callable
import pandas as pd
import numpy as np
import torch
import networkx as nx
from torch_geometric.data import Data, InMemoryDataset
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils import resample
import warnings

warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)

# ğŸ”¹ GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f" Using device: {device}")

# -------------------
# 1. ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤
# -------------------
class AMLtoGraph(InMemoryDataset):
    def __init__(self, root: str, edge_window_size: int = 10,
                 transform: Optional[Callable] = None,
                 pre_transform: Optional[Callable] = None):
        self.edge_window_size = edge_window_size
        super().__init__(root, transform, pre_transform)
        self.data_train, _, self.data_val, _, self.data_test, _ = torch.load(self.processed_paths[0])

    @property
    def raw_file_names(self) -> str:
        return 'HF_TRNS_TRAN_new.csv'

    @property
    def processed_file_names(self) -> str:
        return 'data.pt'

    def preprocess(self, df):
        df.fillna('00', inplace=True)
        df['ff_sp_ai'] = df['ff_sp_ai'].apply(lambda x: 1 if x == 'SP' else 0)
        df = df[df["tran_amt"] >= 10000]
        df["tran_dt"] = pd.to_datetime(df["tran_dt"], format="%Y%m%d")
        train_df = df[(df['tran_dt'].dt.year < 2023) | ((df['tran_dt'].dt.year == 2023) & (df['tran_dt'].dt.month <= 10))]
        val_df = df[(df['tran_dt'].dt.year == 2023) & (df['tran_dt'].dt.month == 11)]
        test_df = df[(df['tran_dt'].dt.year == 2023) & (df['tran_dt'].dt.month > 11)]
        scaler = MinMaxScaler()
        train_df['tran_dt'] = scaler.fit_transform(train_df[['tran_dt']])
        val_df['tran_dt'] = scaler.transform(val_df[['tran_dt']])
        test_df['tran_dt'] = scaler.transform(test_df[['tran_dt']])
        return train_df, val_df, test_df

    def sample_data(self, df, verbose: bool = False):
        """ì •ìƒ ê±°ë˜ 30%, ì‚¬ê¸° ê±°ë˜ë¥¼ ë™ì¼ ê°œìˆ˜ë¡œ ë§ì¶”ëŠ” ìƒ˜í”Œë§ í•¨ìˆ˜"""

        def print_graph_stats(df_part, label=""):
            """ê·¸ë˜í”„ í†µê³„ ì¶œë ¥ í•¨ìˆ˜"""
            G = nx.Graph()
            for _, row in df_part.iterrows():
                G.add_edge(row['wd_fc_ac'], row['dps_fc_ac'], weight=row['tran_amt'])
            print(f"[{label}] ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}, ì—£ì§€ ìˆ˜: {G.number_of_edges()}")

        # ìƒ˜í”Œë§ ì „ ê±°ë˜ ê°œìˆ˜ ì¶œë ¥
        normal_data = df[df['ff_sp_ai'] == 0]
        fraud_data = df[df['ff_sp_ai'] == 1]
        print(f"ì›ë˜ ì •ìƒ ê±°ë˜ ê°œìˆ˜: {len(normal_data)}")
        print(f"ì›ë˜ ì‚¬ê¸° ê±°ë˜ ê°œìˆ˜: {len(fraud_data)}")

        # ìƒ˜í”Œë§
        normal_sampled = normal_data.sample(frac=0.3, random_state=42)
        fraud_sampled = resample(fraud_data, replace=True if len(normal_sampled) > len(fraud_data) else False,
                                 n_samples=len(normal_sampled), random_state=42)

        df_sampled = pd.concat([normal_sampled, fraud_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)

        # ìƒ˜í”Œë§ í›„ ê±°ë˜ ê°œìˆ˜ ì¶œë ¥
        print(f"ìƒ˜í”Œë§ í›„ ì •ìƒ ê±°ë˜ ê°œìˆ˜: {len(normal_sampled)}")
        print(f"ìƒ˜í”Œë§ í›„ ì‚¬ê¸° ê±°ë˜ ê°œìˆ˜: {len(fraud_sampled)}")

        # (ì˜µì…˜) ê·¸ë˜í”„ í†µê³„ ì¶œë ¥
        if verbose:
            print_graph_stats(df, "ìƒ˜í”Œë§ ì „ ì „ì²´ ë°ì´í„°")
            print_graph_stats(df_sampled, "ìƒ˜í”Œë§ í›„ ë°ì´í„°")

        return df_sampled

    def get_edge_df(self, df):
        df['wd_fc_ac'] = df['wd_fc_ac'].astype('category').cat.codes
        df['dps_fc_ac'] = df['dps_fc_ac'].astype('category').cat.codes
        edge_index = torch.tensor([df['wd_fc_ac'].values, df['dps_fc_ac'].values], dtype=torch.long)
        edge_attr = torch.tensor(df[['tran_amt', 'tran_dt', 'tran_tmrg']].values, dtype=torch.float)
        return edge_attr, edge_index

    def get_node_attr(self, df):
        node_attr = torch.tensor(df[["tran_dt", "tran_amt", "tran_tmrg"]].values, dtype=torch.float)
        node_label = torch.tensor(df['ff_sp_ai'].values, dtype=torch.float)
        return node_attr, node_label

    def process(self):
        df = pd.read_csv(self.raw_paths[0])
        train_df, val_df, test_df = self.preprocess(df)

        # trainê³¼ valë§Œ ìƒ˜í”Œë§ ì ìš©, testëŠ” ì›ë³¸ ìœ ì§€
        datasets = {
            'train': self.sample_data(train_df, verbose=False),
            'val': self.sample_data(val_df, verbose=False),
            'test': test_df
        }

        processed_data = {key: self.create_graph_data(df) for key, df in datasets.items()}
        torch.save((processed_data['train'], torch.tensor([]),
                    processed_data['val'], torch.tensor([]),
                    processed_data['test'], torch.tensor([])), self.processed_paths[0])

    def create_graph_data(self, df):
        edge_attr, edge_index = self.get_edge_df(df)
        node_attr, node_label = self.get_node_attr(df)
        return Data(x=node_attr, edge_index=edge_index, edge_attr=edge_attr, y=node_label)


## ë¹ ë¥´ê²Œ ì‹¤í–‰í•˜ê³  ì‹¶ì„ ë•Œ	self.sample_data(train_df, verbose=False)
## ë””ë²„ê¹…ìœ¼ë¡œ ê·¸ë˜í”„ í†µê³„ë„ ë³´ê³  ì‹¶ì„ ë•Œ	self.sample_data(train_df, verbose=True)