{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gretel_client.synthetics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgretel_client\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgretel_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynthetics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_tabular_model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gretel_client.synthetics'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gretel_client\n",
    "import os\n",
    "from gretel_client.synthetics import generate_tabular_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. API 키 설정\n",
    "config = gretel_client.configure_session(api_key=\"my_key\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. 데이터 로드 및 전처리 \n",
    "pd.set_option('display.max_columns', None)\n",
    "path = '../../../../../archive/raw/HI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 3. 데이터 전처리\n",
    "# 2. Timestamp 컬럼을 datetime 객체로 변환 (errors='coerce' 옵션 사용)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%Y/%m/%d %H:%M', errors='coerce')\n",
    "\n",
    "# 3. 'Timestamp' 컬럼에서 NaT인 값 (변환 실패한 값)을 NaN으로 대체\n",
    "df['Timestamp'] = df['Timestamp'].replace({pd.NaT: np.nan})\n",
    "\n",
    "# 4. 결측치 처리 (NaN 값을 삭제 또는 대체)\n",
    "df = df.dropna(subset=['Timestamp'])\n",
    "\n",
    "# 5. DataFrame이 비어있는지 확인\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after removing rows with missing Timestamp values.\")\n",
    "    # 이후 코드를 실행하지 않도록 처리 (예: return)\n",
    "    exit()\n",
    "\n",
    "# 6. datetime 객체를 Unix timestamp로 변환\n",
    "df['Timestamp'] = df['Timestamp'].astype('int64') // 10**9\n",
    "\n",
    "# (선택 사항) 필요에 따라 스케일링 또는 정규화를 수행\n",
    "# 예: MinMaxScaler를 사용하여 0과 1 사이의 값으로 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "df['Timestamp'] = scaler.fit_transform(df[['Timestamp']])\n",
    "\n",
    "# 7. Object 타입 컬럼 원핫 인코딩 (대상 컬럼 줄이기)\n",
    "# 예: 'Receiving Currency', 'Payment Currency', 'Payment Format' 컬럼만 원핫 인코딩\n",
    "df = pd.get_dummies(df, columns=['Receiving Currency', 'Payment Currency', 'Payment Format'])\n",
    "\n",
    "# 8. 'Account', 'Account.1' 컬럼은 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Account'] = label_encoder.fit_transform(df['Account'])\n",
    "df['Account.1'] = label_encoder.fit_transform(df['Account.1'])\n",
    "\n",
    "# 4. 모델 생성 및 학습\n",
    "try:\n",
    "    model = generate_tabular_model(\n",
    "        df.to_csv(index=False),  # DataFrame을 CSV 문자열로 변환\n",
    "        synthetics_engine=\"lstm\", # 또는 다른 지원되는 엔진\n",
    "        field_configs={\n",
    "          \"Timestamp\": {\"data_type\": \"datetime\"} # datetime 타입 명시\n",
    "        }\n",
    "    )\n",
    "    model.train()\n",
    "\n",
    "    # 5. 합성 데이터 생성\n",
    "    synthetic_data = model.create_records(num_records=1000)\n",
    "    synthetic_df = pd.DataFrame.from_records(synthetic_data)\n",
    "    print(synthetic_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Gretel Synthetics processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
